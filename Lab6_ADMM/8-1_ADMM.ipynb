{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Fig/UGA.png\" width=\"30%\" height=\"30%\"></center>\n",
    "<center><h3>Master of Science in Industrial and Applied Mathematics (MSIAM)  -- 1st year</h3></center>\n",
    "<hr>\n",
    "<center><h1>Optimization</h1></center>\n",
    "<center><h2>Lab8: ADMM  </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of an optimization program\n",
    "\n",
    "An optimization program can be practically divided into three parts:\n",
    "* the *run* environment, in which you test, run your program, and display results.\n",
    "* the *problem* part, which contains the function oracles, problem constraints, etc.\n",
    "* the *algorithmic* part, where the algorithms are coded.\n",
    "\n",
    "The main interest of such division is that these parts are interchangeable, meaning that, for instance, the algorithms of the third part can be used of a variety of problems. That is why such a decomposition is widely used.\n",
    "\n",
    "In the present lab, you will use this division:\n",
    "* `8_ADMM.ipynb` will be the *run* environment\n",
    "* `toy_problem.ipynb` and `imaging.ipynb` will be the considered *problems* for this lab\n",
    "* `algoProx.ipynb` and the library `cvxopt` will be used for solving all optimization problems\n",
    "\n",
    "---\n",
    "\n",
    "The following script will allow you to import *notebooks* as if you imported *python files* and will have to be executed at each time you launch Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import start\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ADMM  for solving $\\min_x f(x) + g(x)$\n",
    "\n",
    "> Implement the ADMM in `algoProx.ipynb [Section 2]` as demanded.\n",
    "\n",
    "> Test your implementation on the regression problem of the `Regression3.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import Regression3 as pb\n",
    "reload(pb)\n",
    "\n",
    "import algoProx         # load our algoProx module (from notebook)\n",
    "reload(algoProx)        # reload the module if changed (and saved)\n",
    "from algoProx import *  # import all methods of the module into the current environment\n",
    "\n",
    "\n",
    "rho = 1000.0            # Positive Hyperparameter [TO MODIFY]\n",
    "x0 = np.zeros(pb.n)\n",
    "PREC = 1e-5\n",
    "ITE_MAX = 500\n",
    "\n",
    "\n",
    "x,x_tab,p_tab,d_tab = ADMM(pb.F , pb.f_prox , pb.g_prox , rho , x0 , PREC , ITE_MAX , True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot $F(z_k)$ versus the iterates to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "F = []\n",
    "for i in range(x_tab.shape[0]):\n",
    "    F.append( pb.F(x_tab[i])) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot( F, color=\"black\", linewidth=1.0, linestyle=\"-\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the norms of the primal  and dual residuals.\n",
    "\n",
    "> Modify the value of $\\rho$ in the powers of $10$ between $-3$ and $3$. What do you notice? What is a good value for $\\rho$ for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Group Sparsity\n",
    "\n",
    "\n",
    "> Investigate the signification of the function and regularization in `Regression3.ipynb`. \n",
    "\n",
    "> With the previously found $\\rho$, investigate the support (the set of non-null coordinates) of the points along the iterations. Explain the observed behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For different values of the regularization parameter  Â `lamG` investigate the support and predictive performance of the point given by the ADMM (use the functions `prediction_train(w,PRINT)` and `prediction_test(w,PRINT)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
